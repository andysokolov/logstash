input {
## Uncomment stdin block to accept console input for testing.
#  stdin {
#    type => "ezproxylog"
#    debug => true
#  }
##  Uncomment file block to load a local log file for testing.
#  file {
#    debug => true
#    discover_interval => 1
#    path => [ "/home/kibana/logstash-import/ezproxy/logs/ezproxy*.log" ]
#    start_position => "beginning"
#    type => "ezproxylog"    
#  }
### Listen on port 5544 for syslog messages
  tcp {
    type => "syslog"
    port => 5544
    host => "10.22.4.214"
   debug => true
  }
}

filter {
  if [type] == "syslog" {
    grok {
      # Default EZproxy LogFormat command:
      # LogFormat %h %l %u %t "%r" %s %b
      # Where:
      #  h = Host accessing EZproxy (always IP address).
      #  l = Remote username obtained by idented (identd is not used, so this always inserts -).
      #  u = Username or Session Identifier
      #  t = Date/time of request. Can appear as %{format}
      #  r = Complete request
      #  s = HTTP numeric status code
      #  b = Number of bytes transferred
      # Extract the EZProxy event as syslog_message.
      pattern => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{DATA:syslog_hostname} %{DATA:syslog_tag}: %{GREEDYDATA:syslog_message}"
    }
    grok {
      # Check syslog_logsource to make sure we have an EZProxy log before proceeding.
      match => [ "syslog_tag", "ezproxy.*" ]
      add_tag => [ "ezproxylog" ]
    }
    if "ezproxylog" in [tags] {
      grok {
        # Extract fields from EZProxy event.
        match => [ "syslog_message", "%{IP:clientip} %{USER:ezproxy_remote_username} %{USER:ezproxy_request_username} \[%{HTTPDATE:ezproxy_timestamp}\] %{QS:ezproxy_request_raw} %{NUMBER:http_status} %{NUMBER:bytes} %{QS:referrer} %{QS:user_agent}" ]
      }
      mutate {
        # Assign syslog timestamp and source to new fields. This isn't the timestamp and host we're interested in.
        add_field => [ "logstash_timestamp", "%{@timestamp}" ]
        add_field => [ "logstash_logsource", "%{@source_host}" ]
      } 
      grok {
        # Add field requested_host to the output, matching on URIHOST from requested_uri field.
        match => [ "ezproxy_request_raw", "%{URIPROTO}://(?:%{USER}(?::[^@]*)?@)?(?:%{URIHOST})?(?:%{URIPATH}(?:%{URIPARAM:ezproxy_querystring})?)?" ]
      }
      grok {
        match => [ "ezproxy_querystring", "(?:url|URL)=%{GREEDYDATA:target_url}" ]
      }
      grok {
        match => [ "target_url", "%{URIPROTO}://(?:%{USER}(?::[^@]*)?@)?(?:%{URIHOST:target_hostname})?" ]
      }
      date {
        # Try to set the @timestamp field from the 'timestamp' field (parsed above with
        # grok).
        match => [ "ezproxy_timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
      } 
      mutate {
        # Replace source field values with the values we want from EZProxy.
        replace => [ "@message", "%{syslog_message}" ]
      }
      # Remove duplicate and unimportant fields.
      mutate {
        remove => [ "ezproxy_remote_username", "ezproxy_request_username", "ezproxy_timestamp", "syslog_timestamp", "syslog_message", "@source_host", "@source_path", "@source" ]
      }
      # Do some value-added stuff like GeoIP lookups and User Agent parsing.
       geoip {
         # Try to get GeoIP lookup using value from the 'clientip' field (parsed above with
         # grok).
         source => "clientip"
       }
      useragent {
        source => "user_agent"
      }
    }
  }
}

output {
  #if "ezproxylog" in [tags] {
  # Uncomment stdout{} for debugging.
  #stdout {
  #  debug => true
  #  message => "%{@message}"
  #}
elasticsearch_river {
  #  debug => true
  es_host => "libraryweb.kumc.edu"
  rabbitmq_host => "libraryweb"
  rabbitmq_port => 5672
  user => "guest"
  key => "logstash.ezproxy"
}
}
